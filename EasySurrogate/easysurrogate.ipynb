{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69397b6",
   "metadata": {},
   "source": [
    "# Using EasyVVUQ to generate training data for a forward-UQ  Machine-Learning surrogate\n",
    "\n",
    "Let's start with some definitions:\n",
    "\n",
    "* Forward uncertainty propagation: computing the output distribution of a computational model, given *assumed* probability density functions for the input parameters of the model (see image below). \n",
    "\n",
    "* [EasyVVUQ](https://github.com/UCL-CCS/EasyVVUQ) is VECMA's forward uncertainty propagation toolkit.\n",
    "\n",
    "* Forward surrogate model: an approximation of the input-output map, which can be evaluated at a fraction of the cost of the computational model. \n",
    "\n",
    "* [EasySurrogate](https://github.com/wedeling/EasySurrogate) is VECMA's surrogate modelling toolkit.\n",
    "\n",
    "![](images/forward.png)\n",
    "\n",
    "### Goal \n",
    "\n",
    "Use EasyVVUQ to generate supervised (input parameter, code output) training data on which to train a machine-learning (ML) type of surrogate model. In addition we will\n",
    "\n",
    "* Review some theory behind the sparse-grid methods of EasyVVUQ a ML-method of EasySurrogate.\n",
    "* Spend some time on when you might use ML for building surrogate models.\n",
    "\n",
    "## Installation\n",
    "\n",
    "* EasyVVUQ: via git clone or `pip install easyvvuq`\n",
    "\n",
    "* EasySurrogate: via git clone or `pip install easysurrogate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8027fa",
   "metadata": {},
   "source": [
    "## Sparse-grid UQ in theory\n",
    "\n",
    "### Making a interpolation-based surrogate with 1 uncertain input parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f34614",
   "metadata": {},
   "source": [
    "\n",
    "Let $f^{(1)}(x)$ be a one-dimensional function. We aim to create an interpolation of $f^{(1)}$, denoted by\n",
    "\n",
    "\\begin{align}\n",
    " I^{(l)}f^{(1)}(x) = \\sum_{i=1}^{m_l} f(x_{i}^{(l)})a^{(l)}_i(x).\n",
    " \\label{eq:sc1d}\n",
    "\\end{align}\n",
    "\n",
    "Here, $l$ is the so-called *level* of the interpolant. It is an index which links to a **one-dimensional** set of collocation points $\\{x^{l}_i\\}$, for $i=1,\\cdots, m_l$. We can select these points from different families, typically they'll be the abscissas of some quadrature rule. For instance, a Clenshaw-Curtis (CC) rule can generate different collocation points in $[0,1]$ such that\n",
    "\n",
    "* Level 1: $x^{(1)}_i \\in \\{0.5\\}$,\n",
    "* Level 2: $x^{(2)}_i \\in \\{0.0, 0.5, 1.0\\}$,\n",
    "* Level 3: $x^{(3)}_i \\in \\{0.0, 0.146, 0.5, 0.854, 1.0\\}$.\n",
    "\n",
    "Note that here, the higher level collocation point sets include all points from previous levels. When this is the case, we say that the quadrature rule is **nested**. This leads to efficient sampling plans in higher dimensions, but nestedness is not a strict requirement for sparse grid interpolation or integration. This does lead to 1D quadrature rules which increase exponentially, such that the number of points is given by\n",
    "\n",
    "\\begin{align}\n",
    " m_l = \n",
    " \\begin{cases}\n",
    "  2^{l-1} + 1 & l > 1 \\\\\n",
    "  1 & l = 1\n",
    " \\end{cases}  \n",
    "\\end{align}\n",
    "\n",
    "Finally, the $a^{(l)}_i(x)$ are the basis functions used for interpolation. In the case of the **Stochastic Collocation** (SC) method, these are often (although not necessarily) the Lagrange interpolation polynomials, given by\n",
    "\n",
    "\\begin{align}\n",
    "a^{(l)}_i(x) = \\prod_{\\substack{1\\leq j \\leq m_l \\\\ j \\neq i}} \\frac{x - x_j}{x_i - x_j}\n",
    "\\end{align}\n",
    "\n",
    "A property of the Lagrange polynomial associated with the i-th collocation point is that $a^{(l)}_i(x_i) = 1$ at this point, and $a^{(l)}_i(x_j) = 0$ at all other collocation points $x_j$. The interpolation $I^{(l)}f^{(1)}$ will therefore exactly reproduce the code outputs $f^{(1)}(x_i)$ at the collocation points $x_i$.\n",
    "\n",
    "Let us define the following difference formulas for interpolation in 1D:\n",
    "\n",
    "\\begin{align}\n",
    " \\Delta^{(l)} f^{(1)} := I^{(l)}f^{(1)} - I^{(l-1)}f^{(1)}\\quad\\mathrm{where}\\quad\n",
    " I^{(0)}f^{(1)}:=0.\n",
    " \\label{eq:Delta1d}\n",
    "\\end{align}\n",
    "\n",
    "That is, $ \\Delta^{(l)} f^{(1)}$ is just the difference between the interpolations at successive levels. These difference formulas are often used in both sparse-grid interpolation (and quadrature), see the figure below.\n",
    "\n",
    "![](images/fig1.png)\n",
    "\n",
    "\n",
    "When interpolating a level $l-1$ interpolant using a level $l$ interpolating we retrieve the former, i.e.\n",
    "\n",
    "\\begin{align}\n",
    " I^{(l)}\\left(I^{(l-1)}f^{(l)}\\right) = I^{(l-1)}f^{(l)}.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Thus, a lower level interpolant can be exactly interpolated by a higher level interpolant (which is true for both nested and non-nested collocation points), see Figure below:\n",
    "\n",
    "![](images/fig2.png)\n",
    "*The blue solid line is the exact 1D function $f^{(1)}$. The red striped line is a (non-nested) level $l$ interpolant. The green striped line is a lower-level $l-1$ counterpart, constructed from function evaluations at  the green star symbols.. If we evaluate the level $l-1$ interpolant at the level $l$ collocation, we obtain the blue squares. Clearly, if these function values are used to construct a level $l$ interpolant of $I^{(l-1)}f^{(1)}$, which would be $I^{(l)}\\left(I^{(l-1)}f^{(1)}\\right)$, we just retrieve $I^{(l-1)}f^{(1)}$.*\n",
    "\n",
    "We can therefore write the difference formula as\n",
    "\n",
    "\\begin{align}\n",
    " \\Delta^{(l)}f^{(1)} = I^{(l)}f^{(1)} - I^{(l)}\\left(I^{(l-1)}f^{(1)}\\right) = \\sum_{i = 1}^{m_l}f(x^{(l)}_i)a^{(l)}_i - \\sum_{i=1}^{m_l}I^{(l-1)}f^{(1)}(x^{(l)}_i)a^{(l)}_i = \\nonumber\\\\\n",
    " \\sum_{i=1}^{m_l}\\left[f(x^{(l)}_i) - I^{(l-1)}f^{(1)}(x^{(l)}_i)\\right]a^{(l)}_i = \\sum_{i=1}^{m_l}s^{(l)}_ia^{(l)}_i.\n",
    " \\label{eq:diff0}\n",
    "\\end{align}\n",
    "\n",
    "Here, $w^{(l)}_i:=f(x^{(l)}_i) - I^{(l-1)}f^{(1)}(x^{(l)}_i)$ is the **hierarchical surplus**, defined as the difference between the code output at a collocation point $x^{(l)}_i$ at level $l$, minus the level $l-1$ polynomial approximation of the code output at the same location. This can be thought of as a local measure of the accuracy of the interpolation. Furthermore, we can also write the interpolation $I^{(l)}f^{(1)}(x)$ in terms of the difference formulas, in which case the $a^{l}_i$ basis function will form a hierarchical basis as\n",
    "\n",
    "\\begin{align}\n",
    " I^{(L)}f^{(1)} = \\sum_{l=1}^L \\Delta^{(l)}f^{(1)} = \\sum_{l=1}^L\\sum_{i=1}^{m_l}w^{(l)}_i a^{(l)}_i\n",
    " \\label{eq:diff1}\n",
    "\\end{align}\n",
    "\n",
    "Hence, to obtain a level $L$ interpolant, we can just create a telescopic sum of the difference formulas, which is the first equality above. The second equality is obtained by simply plugging in the formula for $\\Delta^{(l)}f^{(1)}$, and it shows that the $a^{(l)}_i$ form a hierarchical basis due to summation over $l$, which increases the number collocation point $m_l$ at every new level. This is also sketched in the Figure below, which assumes linear basis functions for simplicity.\n",
    "\n",
    "![](images/fig3.png)\n",
    "*Top left is a standard linear (finite-element) basis, with below it a corresponding linear interpolant. Top right displays a linear hierarchical basis. Below it we show a series of 3 hierarchical interpolants ($L=1,2$ and $3$) and the hierarchical surplus coefficients $w^{(l)}_i$ used in their construction. Figure recreated from*\n",
    "\n",
    "**Why should we care?**\n",
    "\n",
    "The formula above is the same as $I^{(l)}f^{(1)}$ in the beginning, as both are 1D interpolation formulas, only written differently, so why should we complicate things with a hierarchical notation? \n",
    "\n",
    "One advantage of adopting the hierarchical notation is that it naturally allows for **refinement**, i.e. adding more points to an existing sampling plan, by adding another level. If we select a nested quadrature rule, adding another level means we only have to evaluate the (expensive) code at a relatively small number of *new* points, the other points are quaranteed to be present in one or more of the previous levels, see the CC example at the beginning of this section.\n",
    "\n",
    "In the case more than one uncertain input, sampling plans are create using **tensor products of 1D collocation points**. Here, **a hierarchical construction leads to a sparse sampling plan**, with much less code evaluations compared to \"standard\" sampling plans.\n",
    "\n",
    "![](images/drawing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b90cba",
   "metadata": {},
   "source": [
    "## Sparse-grid UQ in practice\n",
    "\n",
    "### Model description\n",
    "\n",
    "Let's review the basic model. It is a simulation of a vertical deflection of a round metal \n",
    "tube suspended on each end in response to a force applied at certain point ```a``` along its length. \n",
    "Our goal is to determine the influence of the input parameters on the vertical deflection at point ```a```.\n",
    "\n",
    "The usage of the application is:\n",
    "\n",
    "```beam <input_file>```\n",
    "\n",
    "It outputs calculated displacements to a file called `output.json`. Its content will look like \n",
    "\n",
    "```{'g1': x, 'g2': y, 'g3': y}```\n",
    "\n",
    "In order to produce statistically significant results, EasyVVUQ needs to run a number of model evaluations\n",
    " appropriately selecting input arguments from a given sample parameter space. \n",
    " Once selected, input parameters need to be transformed into a format understandable by the application. \n",
    "Our application takes a single file as an input and the transformation may be based on a single template file,\n",
    "called `beam.template`, with the following content:\n",
    "\n",
    "```{\"outfile\": \"$outfile\", \"F\": $F, \"L\": $L, \"a\": $a, \"D\": $D, \"d\": $d, \"E\": $E}```\n",
    "\n",
    "The template will be used to generate files called `input.json` that will be the input to each run of beam.\n",
    "All placeholders (signified by the $ delimeter) will be replaced by concrete values from the sample parameter space. \n",
    "\n",
    "<img src=\"images/simply_supported_beam.png\" width=\"500\" height=\"300\" />\n",
    "\n",
    "The tube has an inner and outer diameter\n",
    "\n",
    "<img src=\"images/tube-diameters.png\" width=\"200\" height=\"100\" />\n",
    "\n",
    "The parameters are self explanatory, and the model is just a simple analytical function, which can be found [here](https://openturns.github.io/openturns/latest/usecases/use_case_deflection_tube.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0b773702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import easyvvuq as uq\n",
    "import chaospy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from easyvvuq.actions import CreateRunDirectory, Encode, Decode, ExecuteLocal, Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "96435f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory in which the code samples will be stored\n",
    "WORK_DIR = '/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "af28fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters\n",
    "params = {\n",
    "    \"F\": {\"type\": \"float\", \"default\": 1.0}, \n",
    "    \"L\": {\"type\": \"float\", \"default\": 1.5}, \n",
    "    \"a\": {\"type\": \"float\", \"min\": 0.7, \"max\": 1.2, \"default\": 1.0}, \n",
    "    \"D\": {\"type\": \"float\", \"min\": 0.75, \"max\": 0.85, \"default\": 0.8},\n",
    "    \"d\": {\"type\": \"float\", \"default\": 0.1},\n",
    "    \"E\": {\"type\": \"float\", \"default\": 200000},\n",
    "    \"outfile\": {\"type\": \"string\", \"default\": \"output.json\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063ebe3",
   "metadata": {},
   "source": [
    "Below we create the encoder and decoder objects that are capable of reading the input and output files that are described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ac61c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = uq.encoders.GenericEncoder(template_fname='beam.template', delimiter='$', target_filename='input.json')\n",
    "decoder = uq.decoders.JSONDecoder(target_filename='output.json', output_columns=['g1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df576c",
   "metadata": {},
   "source": [
    "As our model is a toy problem, we can execute it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c6e3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute = ExecuteLocal('{}/beam input.json'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1570b6",
   "metadata": {},
   "source": [
    "However, in many cases the model will be too expensive for local executing. In this case the VECMA tools [QCG-PilotJob](https://github.com/vecma-project/QCG-PilotJob) or [FabSim3](https://github.com/djgroen/FabSim3) can be used in combination with EasyVVUQ to submit the ensemble to HPC resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512bc0c",
   "metadata": {},
   "source": [
    "Now we are combine all actions we want to execute into an Actions object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a9ff6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = Actions(CreateRunDirectory(root=WORK_DIR, flatten=True), Encode(encoder), execute, Decode(decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d75253",
   "metadata": {},
   "source": [
    "An EasyVVUQ campaign is created, and the parameters and actions are supplied to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "953fa8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = uq.Campaign(name='beam_SC', params=params, actions=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3a8fe",
   "metadata": {},
   "source": [
    "We simply copy the input distributions from [here](https://openturns.github.io/openturns/latest/usecases/use_case_deflection_tube.html):\n",
    "\n",
    "\n",
    "* F: Normal(1,0.1)\n",
    "* L: Normal(1.5,0.01)\n",
    "* a: Uniform(0.7,1.2)\n",
    "* D: Triangular(0.75,0.8,0.85)\n",
    "* d: Triangular(0.09,0.1,0.11)\n",
    "* E: Normal(200000,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a967fc5a",
   "metadata": {},
   "source": [
    "Let's start with just 2 inputs, and visualize the sparse grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a3737c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the input distributions of the parameters that we which to vary\n",
    "vary = {\n",
    "    \"F\": cp.Normal(1, 0.1),\n",
    "    \"L\": cp.Normal(1.5, 0.01),\n",
    "    \"a\": cp.Uniform(0.7, 1.2),\n",
    "    \"D\": cp.Triangle(0.75, 0.8, 0.85),\n",
    "    \"d\": cp.Triangle(0.09, 0.1, 0.11),\n",
    "    \"E\": cp.Normal(200000, 2000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3621575",
   "metadata": {},
   "source": [
    "Here we select the (sparse) Stochastic Collocation sampler. Increase the `polynomial_order` of the sampler object below to create sparse grids with more levels. Also compare this to a standard non-sparse sampling plan by setting `sparse=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a847b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampling points = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler = uq.sampling.SCSampler(vary=vary, polynomial_order=1, quadrature_rule='C', growth=True, sparse=True)\n",
    "campaign.set_sampler(sampler)\n",
    "\n",
    "# plot the sampling plan of the (first) two input dimensions\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, xlabel='x_1', ylabel='x_2')\n",
    "# the xi_d array contains the N x d sampling points, with N being the number of points and d the number of inputs\n",
    "ax.plot(sampler.xi_d[:,0], sampler.xi_d[:, 1], 'ro')\n",
    "# print the number of points to screen\n",
    "print(\"Number of sampling points = %d\" % sampler.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a167b",
   "metadata": {},
   "source": [
    "The command below executes the ensemble and collects the results from the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a7e35057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sampling points = 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 19.07it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "refine = True\n",
    "if refine:\n",
    "    sampler.next_level_sparse_grid()\n",
    "    # plot the sampling plan of the (first) two input dimensions\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, xlabel='x_1', ylabel='x_2')\n",
    "    # the xi_d array contains the N x d sampling points, with N being the number of points and d the number of inputs\n",
    "    ax.plot(sampler.xi_d[:,0], sampler.xi_d[:, 1], 'ro')\n",
    "    # print the number of points to screen\n",
    "    print(\"Number of sampling points = %d\" % sampler.n_samples)\n",
    "# execute ensemble\n",
    "campaign.execute().collate(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a4996f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = campaign.get_collation_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2aa1c",
   "metadata": {},
   "source": [
    "The command below peforms the analysis step by post-processing of the ensemble results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "99fbdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = campaign.analyse(qoi_cols=['g1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77aabeb",
   "metadata": {},
   "source": [
    "Let's plot some Sobol sensitivity indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a14b2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobols_first = results.sobols_first()\n",
    "param_names = sobols_first['g1'].keys()\n",
    "sobols_first = np.array(list(sobols_first['g1'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f6cc289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[4, 8])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel(r'first-order Sobol index', fontsize=14)\n",
    "# find max quad order for every parameter\n",
    "ax.bar(range(sobols_first.size), height=sobols_first.flatten())\n",
    "ax.set_xticks(range(sobols_first.size))\n",
    "ax.set_xticklabels(param_names)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c06f074",
   "metadata": {},
   "source": [
    "Now, try the same the same thing with all 6 parameters included in `vary`. Refine the grid multiple times to get an idea of the cost involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcf46d",
   "metadata": {},
   "source": [
    "Notice that it can still become expensive. In the standard SC method, the number of code evaluations equals $m^d$, where $m$ is the number of points in 1D, and $d$ is the number of uncertain inputs. In the case of sparse grids, the exponent $d$ is applied of $log(m)$ instead of $m$. Hence the cost still rises exponentially, although not as fast as with the standard SC method. This makes it possible to increase the number of inputs somewhat, but not really significantly.\n",
    "\n",
    "So what can you do if you have 20, 30 or more inputs? One option is to still use a hierarchical sparse-grid construction, but try to refine only those inputs which have a significant impact on the output. Here, we have refined all parameters to the same extent.\n",
    "\n",
    "Another option, which will discuss below, is to use machine learning to create a surrogate model, trained on input-output data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff034d0",
   "metadata": {},
   "source": [
    "## Deep active subspaces in theory\n",
    "\n",
    "\n",
    "The Active Subspace method, introduced by [1], is a class of methods for forward propagation of uncertainty in high-dimensional input spaces. It attempts to circumvent the curse of dimensionality by dimension reduction of the input space. Specifically, it projects the input vector ${\\bf x}\\in\\mathbb{R}^D$ to a lower-dimensional subspace ${\\bf y}\\in\\mathbb{R}^d$, via a tall-and-skinny matrix $W_1\\in\\mathbb{R}^{D\\times d}$ of orthogonal basis vectors, such that $W_1^TW_1 = I_d$, where $d<D$ and $I_d$ is the $d$-dimensional identity matrix. The active subspace is thus given by\n",
    "\n",
    "\\begin{align}\n",
    "{\\bf y} = W_1^T{\\bf x} \\in\\mathbb{R}^d,\n",
    "\\label{eq:active}\n",
    "\\end{align}\n",
    "\\noindent\n",
    "where the main idea is that the dimension reduction simplifies the task of obtaining an accurate surrogate model. If we denote this surrogate by $g$, we thus want to find a model that satisfies\n",
    "\n",
    "\\begin{align}\n",
    "f({\\bf x})\\approx g\\left({\\bf y}\\right) = g\\left(W_1^T{\\\n",
    "\\bf x}\\right).\n",
    "\\label{eq:g}\n",
    "\\end{align}\n",
    "\n",
    "### Classical means of finding $W_1$\n",
    "\n",
    "Because ${\\bf y}$ is a linear transformation of the inputs ${\\bf x}$, it opens up the possibility of findings directions along which the model varies most. This is especially useful if a model varies significantly in a direction that is not aligned with the coordinate axes of ${\\bf x}$. In \"classical\" active subspaces, dimension reduction is achieved by rotating the coordinate system such that it is aligned with the directions of most variability, after which only the most dominant directions are retained. To find these directions, the following average gradient matrix is constructed:\n",
    "\n",
    "\\begin{align}\n",
    " C = \\int \\left(\\nabla f\\left({\\bf x}\\right)\\right)\\left(\\nabla f\\left({\\bf x}\\right)\\right)^T p(\\bf x)d{\\bf x}\n",
    " \\label{eq:C}\n",
    "\\end{align}\n",
    "\\noindent\n",
    "Here, $p({\\bf x})$ is the chosen probability density function (pdf) of the inputs ${\\bf x}$. Since $C$ is a symmetric, positive semi-definite matrix, it has the following spectral decomposition\n",
    "\n",
    "\\begin{align*}\n",
    " C = [W_1 W_2]\\left[\n",
    "\\begin{matrix}\n",
    "\\Lambda_1 & 0 \\\\\n",
    "0 & \\Lambda_2\n",
    "\\end{matrix} \n",
    " \\right][W_1 W_2]^T.\n",
    "\\end{align*}\n",
    "\n",
    "Hence the matrix $W_1$, used to project ${\\bf x}$ to ${\\bf y}$ in, are the first $d$ eigenvectors of $C$, which in turn correspond to the $d$ largest eigenvalues in $\\Lambda_1$. These $d$ eigenvectors form an orthonormal basis aligned with the directions of most variability. Note that $C$ is averaged over $p({\\bf x})$, and that in practise, the integral in in $C$ is often approximated using a Monte Carlo approach.\n",
    "\n",
    "The approach described here is intuitive, and has nice theoretical properties, such as computable error bounds. The downside however, is that the gradient $\\nabla f({\\bf x})$ must be available. This requires the availability of an adjoint solver, or one must approximate the gradients using for instance finite differences. This downside has prompted the development of other active subspace methods which do not require access to the gradient. Some of these methods involve Gaussian processes, whereas others use deep learning. We will focus on the latter.\n",
    "\n",
    "### Deep active subspaces\n",
    "\n",
    "In [2], an approach is described in which artificial neural networks (ANNs) are used for $g$, and where $W_1$ is found using back propagation. Like the classical active subspace method, the construction ${\\bf y} = W_1^T{\\bf x}$ is retained. Moreover, the column vectors of $W_1$ still form an orthogonal basis. The difference is that the column vectors of $W_1$ are no longer the eigenvectors of the gradient matrix $C$, but instead are constructed using Gram-Schmidt orthogonalization. As such, $W_1$ is parametrized by a matrix $Q$ of the same dimension ($\\in\\mathrm{R}^{D\\times d}$), where the non-orthonormal column vectors ${\\bf q}_i\\in\\mathbb{R}^D$ are made orthonormal via\n",
    "\n",
    "\\begin{align}\n",
    " {\\bf w}_i = {\\bf q}_i - \\sum_{j=1}^{i-1}\\left(\\frac{{\\bf w}_j^T{\\bf q}_i}{{\\bf w}_j^T{\\bf w}_j}\\right){\\bf w}_j, \\quad i = 1,\\cdots, d.\n",
    " \\label{eq:GS}\n",
    "\\end{align}\n",
    "\n",
    "That is, we start with ${\\bf w}_1 := {\\bf q}_1$, and for all subsequent vectors ${\\bf q}_i$ we subtract the projections of ${\\bf q}_i$ onto each vector ${\\bf w}_j$ which has previously been orthogonalized. This leaves us with a orthogonal basis $ \\left[{\\bf w}_1({\\bf q}_1)\\;\\;{\\bf w}_2({\\bf q}_1, {\\bf q}_2)\\;\\;\\cdots\\;\\;{\\bf w}_d({\\bf q}_1,{\\bf q}_2\\,\\cdots,{\\bf q}_d)\\right]$. Finally, to obtain an orthonormal basis, each column vector is divided by its length. such that our final weight matrix becomes\n",
    "\n",
    "\\begin{align}\n",
    "W_1(Q) = \\left[\\frac{{\\bf w}_1({\\bf q}_1)}{\\lVert{\\bf w}_1({\\bf q}_1)\\rVert_2}\\;\\;\\frac{{\\bf w}_2({\\bf q}_1, {\\bf q}_2)}{\\lVert{\\bf w}_2({\\bf q}_1, {\\bf q}_2)\\rVert_2}\\;\\;\\cdots\\;\\;\\frac{{\\bf w}_d({\\bf q}_1,{\\bf q}_2\\,\\cdots,{\\bf q}_d)}{\\lVert{\\bf w}_d({\\bf q}_1,{\\bf q}_2\\,\\cdots,{\\bf q}_d)\\rVert_2}\\right].\n",
    "\\label{eq:W1}\n",
    "\\end{align}\n",
    "\n",
    "Note that the projection ${\\bf y} = \\Phi\\left(W_1^T{\\bf x}\\right) = W_1^T{\\bf x}$ also occurs in a layer of a neural network if the activation function $\\Phi\\left(\\cdot\\right)$ is linear. Thus, we can interpret the matrix $W_1$ as a weight matrix of the first hidden layer (with $d$ neurons and linear activation), connected to an input layer through which ${\\bf x}$ is passed. Each column vector ${\\bf w}_i$ contains the all weights connecting the input layer to the i-th neuron of the first hidden layer, see the figure below. Since the first hidden layer has only $d$ neurons, and its weight matrix is determined from a Gram-Schmidt procedure, we call the layer the Deep Active Subspace (DAS) layer.\n",
    "\n",
    "<img src=\"images/nn1.png\" width=700 height=700>\n",
    "\n",
    "The surrogate $g({\\bf y})$ is the ANN from the DAS layer onward, see the figure below. Each hidden layer has a weight matrix $W_i\\in\\mathbb{R}^{p + 1\\times p}$, assuming that all hidden layers have $p$ neurons plus 1 bias neuron. As per usual, these weight matrices are optimized through the back propagation algorithm, in which the gradient $\\partial L/\\partial W_i$ is computed, where $L$ is the loss function.\n",
    "\n",
    "<img src=\"images/nn2.png\" width=700 height=700>\n",
    "\n",
    "The situation in the DAS layer is different. Since $W_1=W_1(Q)$, we need to optimize $Q$ instead of the weight matrix, and therefore back propagation requires $\\partial L/\\partial Q$ instead of $\\partial L/\\partial W_1$. The authors of [2] suggest to use automatic differentiation. This does make sense, since although ${\\bf w}_k/\\Vert {\\bf w}_k \\rVert_2$ is algebraic and differentiable, it quickly becomes a complicated expression involving a very large number of $q_{ij}$ terms. Here, $q_{ij}$ are the $D$ entries, $i=1,\\cdots,D$, of ${\\bf q}_j$. That said, it is possible to use matrix calculus to find a simple expression for $\\partial L /\\partial Q$, which is the approach implemented in EasySurrogate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cb7f7",
   "metadata": {},
   "source": [
    "## Deep active subspaces in practise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d626ddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:23<00:00, 21.42it/s]\n"
     ]
    }
   ],
   "source": [
    "LHC_campaign = uq.Campaign(name='beam_LHC', params=params, actions=actions)\n",
    "LHC_sampler = uq.sampling.quasirandom.LHCSampler(vary, max_num=500)\n",
    "LHC_campaign.set_sampler(LHC_sampler)\n",
    "LHC_campaign.execute().collate(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "604d7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = LHC_campaign.get_collation_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1fd3994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easysurrogate as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5b7935ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features ['F', 'L', 'a', 'D', 'd', 'E']\n",
      "Extracting output data ['g1'] \n"
     ]
    }
   ],
   "source": [
    "surr_campaign = es.Campaign()\n",
    "params, samples = surr_campaign.load_easyvvuq_data(LHC_campaign, ['g1'])\n",
    "samples = samples['g1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9d8f7a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DAS_Surrogate Object\n",
      "Creating Feature Engineering object\n",
      "Using  400/500 samples to train the ML model\n",
      "done preparing data\n",
      "===============================\n",
      "Neural net parameters\n",
      "===============================\n",
      "Number of layers = 4\n",
      "Number of features = 6\n",
      "Loss function = squared\n",
      "Number of neurons per hidden layer = 100\n",
      "Number of output neurons = 1\n",
      "Activation hidden layers = tanh\n",
      "Activation output layer = linear\n",
      "This neural network has 10513 weights.\n",
      "===============================\n",
      "===============================\n",
      "Training Deep Active Subspace Neural Network...\n",
      "Batch 0 learning rate 0.001 loss: 1.0296673832827703\n",
      "Batch 1000 learning rate 0.001 loss: 0.0007581115441239123\n",
      "Batch 2000 learning rate 0.001 loss: 0.0008529064211351558\n",
      "Batch 3000 learning rate 0.001 loss: 0.00040085479770584574\n",
      "Batch 4000 learning rate 0.001 loss: 0.00041933227812293475\n",
      "Batch 5000 learning rate 0.001 loss: 0.0005570865285046106\n",
      "Batch 6000 learning rate 0.001 loss: 0.0005584903905418715\n",
      "Batch 7000 learning rate 0.001 loss: 0.000621030789247949\n",
      "Batch 8000 learning rate 0.001 loss: 0.0006037016542833631\n",
      "Batch 9000 learning rate 0.001 loss: 0.0007241198266155188\n"
     ]
    }
   ],
   "source": [
    "#train a DAS network\n",
    "D = len(vary)\n",
    "d = 2\n",
    "\n",
    "surrogate = es.methods.DAS_Surrogate()\n",
    "surrogate.train(params, samples, d, n_iter=10000, n_layers=4, n_neurons=100, test_frac = 0.2)\n",
    "\n",
    "dims = surrogate.get_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "00ddada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative error on training set = 0.0063\n",
      "Relative error on test set = 0.0070\n"
     ]
    }
   ],
   "source": [
    "# run the trained model forward at training locations\n",
    "n_mc = dims['n_train']\n",
    "pred = np.zeros([n_mc, dims['n_out']])\n",
    "for i in range(n_mc):\n",
    "    pred[i,:] = surrogate.predict(params[i])\n",
    "   \n",
    "train_data = samples[0:dims['n_train']]\n",
    "rel_err_train = np.linalg.norm(train_data - pred)/np.linalg.norm(train_data)\n",
    "\n",
    "# run the trained model forward at test locations\n",
    "pred = np.zeros([dims['n_test'], dims['n_out']])\n",
    "for idx, i in enumerate(range(dims['n_train'], dims['n_samples'])):\n",
    "    pred[idx] = surrogate.predict(params[i])\n",
    "test_data = samples[dims['n_train']:]\n",
    "rel_err_test = np.linalg.norm(test_data - pred)/np.linalg.norm(test_data)\n",
    "\n",
    "print('Relative error on training set = %.4f' % rel_err_train)\n",
    "print('Relative error on test set = %.4f' % rel_err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5b19cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DAS_analysis object\n"
     ]
    }
   ],
   "source": [
    "analysis = es.analysis.DAS_analysis(surrogate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35c6a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters ordered from most to least important:\n",
      "[[2 3 0 1 5 4]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_mc = 10**4\n",
    "params = np.array([p.sample(n_mc) for p in sampler.vary.get_values()]).T\n",
    "idx, mean = analysis.sensitivity_measures(params)\n",
    "params_ordered = np.array(list(sampler.vary.get_keys()))[idx[0]]\n",
    "\n",
    "fig = plt.figure('sensitivity', figsize=[4, 8])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel(r'$\\int\\frac{\\partial ||y||^2_2}{\\partial x_i}p({\\bf x})d{\\bf x}$', fontsize=14)\n",
    "# find max quad order for every parameter\n",
    "ax.bar(range(mean.size), height = mean[idx].flatten())\n",
    "ax.set_xticks(range(mean.size))\n",
    "ax.set_xticklabels(params_ordered)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45e214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
